{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "from sqlalchemy.exc import IntegrityError\n",
    "from sqlalchemy import select,text,Column,Table , ForeignKeyConstraint\n",
    "from sqlalchemy import create_engine,MetaData,insert\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating an empty database in MS-SQL-SERVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_sql_server_url=\"mssql+pyodbc://mainroot:1234567890@DESKTOP-UEP03CP/master?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "master_sql_server_engine=create_engine(master_sql_server_url)\n",
    "master_sql_server_metadata=MetaData()\n",
    "master_sql_server_metadata.reflect(bind=master_sql_server_engine,schema=\"dbo\")\n",
    "\n",
    "with master_sql_server_engine.connect() as conn:\n",
    "    conn.execution_options(isolation_level=\"AUTOCOMMIT\")\n",
    "    conn.execute(text(\"CREATE DATABASE classicmodels;\"))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Establishing the main conections of program\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysql_url=\"mysql+pymysql://root:1234567890@localhost/classicmodels?\"\n",
    "mysql_engine=create_engine(mysql_url)\n",
    "mysql_metadata=MetaData()\n",
    "mysql_metadata.reflect(bind=mysql_engine)\n",
    "\n",
    "sql_server_url=\"mssql+pyodbc://mainroot:1234567890@DESKTOP-UEP03CP/classicmodels?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "sql_server_engine=create_engine(sql_server_url)\n",
    "sql_server_metadata=MetaData()\n",
    "sql_server_metadata.reflect(bind=sql_server_engine,schema=\"dbo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The main used functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes copy the tables from source metadata to target metadata \n",
    "def creating_tables(source_metadata:MetaData,target_metadata:MetaData,show_time:float=0):\n",
    "    for table in source_metadata.sorted_tables:\n",
    "        print(f\"we are in the table {table}\")\n",
    "        col_list=[]\n",
    "        for column in table.columns:\n",
    "            new_column=Column(\n",
    "            column.name,\n",
    "            column.type,\n",
    "            nullable=column.nullable,\n",
    "            primary_key=column.primary_key,\n",
    "            autoincrement=column.autoincrement,\n",
    "            index=column.index,\n",
    "            unique=column.unique,\n",
    "            default=column.default,   \n",
    "            )\n",
    "            col_list.append(new_column)\n",
    "        new_table=Table(table.name,target_metadata)\n",
    "        for new_col in col_list:        \n",
    "            new_table.append_column(new_col,)\n",
    "            print(f\"{new_col} is appended\")\n",
    "    time.sleep(show_time)\n",
    "    clear_output(wait=True)\n",
    "    print(\"All tables are succsfully created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function extracts the foreign key data\n",
    "def create_fk_data_dics(source_metadata:MetaData):\n",
    "    fk_data_list=[]\n",
    "    for table in source_metadata.sorted_tables:\n",
    "        for column in table.columns:\n",
    "            for fk_data in column.foreign_keys:\n",
    "                fk_data_list.append({\n",
    "                    \"source_column\":column.name,\n",
    "                    \"source_table\":table.name,\n",
    "                    \"target_column\":fk_data.column.name,\n",
    "                    \"target_table\":fk_data.column.table.name,\n",
    "                })\n",
    "    print(\"list of FK_data dictionaries is complete\")\n",
    "    return fk_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this function using the FK_data to formulate a FK_constraints and append them to the target metadata\n",
    "def append_fk(target_metadata:MetaData,fk_data_list):\n",
    "    for table in target_metadata.sorted_tables:\n",
    "        for fk_data_dic in fk_data_list:    \n",
    "            if table.name == fk_data_dic[\"source_table\"]:\n",
    "                source_column= table.columns[fk_data_dic[\"source_column\"]]\n",
    "                target_table=  target_metadata.tables[fk_data_dic[\"target_table\"]]          \n",
    "                target_column= target_metadata.tables[fk_data_dic[\"target_table\"]].columns[fk_data_dic[\"target_column\"]]\n",
    "                fk_constraint=ForeignKeyConstraint([source_column],[target_column])\n",
    "                table.append_constraint(constraint=fk_constraint)\n",
    "    print(f\"the FK_constraints is added to the target metadata\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting and Uplodaing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this function is used to extract the data from the source database (mysql) and upload the data into target database (sql-server)\n",
    "def extracting_and_uplading(source_engine:sqlalchemy.Engine,source_metadata:MetaData,target_engine:MetaData):\n",
    "    with source_engine.connect() as conn:\n",
    "        for table in source_metadata.sorted_tables:\n",
    "            stmt = select(table)\n",
    "            data = conn.execute(stmt).fetchall()\n",
    "            with target_engine.connect() as sql:\n",
    "                for row in data:                \n",
    "                    # Convert row into a dictionary\n",
    "                    row_dict={}\n",
    "                    for column , value in zip(table.columns,row):\n",
    "                        row_dict[column.name]=value\n",
    "                    # Prepare the insert statement\n",
    "                    try:\n",
    "                        print(row)\n",
    "\n",
    "                        stmt_2 = insert(table).values(row_dict)\n",
    "                        sql.execute(stmt_2)\n",
    "                        sql.commit()\n",
    "                    except IntegrityError:\n",
    "                        print(\"IntegrityError probably ( prexisted row ) \")\n",
    "    time.sleep(0.5)\n",
    "    clear_output(wait=True)\n",
    "    print(\"All tables are succsfully uploaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tables are succsfully created\n",
      "list of FK_data dictionaries is complete\n",
      "the FK_constraints is added to the target metadata\n"
     ]
    }
   ],
   "source": [
    "creating_tables(source_metadata=mysql_metadata,target_metadata=sql_server_metadata,)\n",
    "fk_data_list=create_fk_data_dics(source_metadata=mysql_metadata)\n",
    "append_fk(sql_server_metadata,fk_data_list=fk_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to change some data types into a suitable data types for sql-server\n",
    "for table in sql_server_metadata.sorted_tables:\n",
    "    for column in table.columns:\n",
    "        if isinstance(column.type,sqlalchemy.dialects.mysql.types.MEDIUMTEXT):\n",
    "            column.type=sqlalchemy.types.VARCHAR()\n",
    "        elif isinstance(column.type,sqlalchemy.dialects.mysql.types.MEDIUMBLOB):\n",
    "            column.type=sqlalchemy.types.VARCHAR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the metadata\n",
    "sql_server_metadata.create_all(bind=sql_server_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting and uploading the data the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tables are succsfully uploaded\n"
     ]
    }
   ],
   "source": [
    "extracting_and_uplading(source_engine=mysql_engine,source_metadata=mysql_metadata,target_engine=sql_server_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
